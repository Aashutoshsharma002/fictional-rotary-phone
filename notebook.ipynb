{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "# import vmmr_utils # \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cars = {\n",
    "    \"honda_civic_1998\": [\"honda_civic_1997\", \"honda_civic_1998\"], # available \"honda_civic_1999\"\n",
    "    \"honda_accord_1997\": [\"honda_accord_1996\", \"honda_accord_1997\"], # available \"honda_accord_1998\"\n",
    "    \"ford_f150_2006\": [\"ford_f150_2005\", \"ford_f150_2006\", \"ford_f150_2007\"], # available \"ford_f150_2008\"\n",
    "    \"chevrolet_silverado_2004\": [\"chevrolet_silverado_2003\", \"chevrolet_silverado_2004\"], # available \"chevrolet_silverado_2005\"\n",
    "    \"toyota_camry_2014\": [\"toyota_camry_2012\", \"toyota_camry_2013\", \"toyota_camry_2014\", \"toyota_camry_le_2012\", \"toyota_camry_le_2013\", \"toyota_camry_le_2014\", \"toyota_camry_se_2012\", \"toyota_camry_se_2013\", \"toyota_camry_xle_2012\", \"toyota_camry_xle_2013\"],\n",
    "    \"nissan_altima_2014\": [\"nissan_altima_2013\", \"nissan_altima_2014\", \"nissan_altima_2015\"], # available \"nissan_altima_2016\"\n",
    "    \"toyota_corolla_2013\": [\"toyota_corolla_2011\", \"toyota_corolla_2012\", \"toyota_corolla_2013\", \"toyota_corolla_ce_2012\", \"toyota_corolla_le_2012\", \"toyota_corolla_le_2013\", \"toyota_corolla_s_2011\", \"toyota_corolla_s_2012\"],\n",
    "    \"dodge_ram_2001\": [\"dodge_ram_1500_2000\", \"dodge_ram_1500_2001\", \"dodge_ram_1500_1999\", \"dodge_ram_1500_1998\", \"dodge_ram_1500_1997\", \"dodge_ram_1500_1996\", \"dodge_ram_1500_1995\"],\n",
    "    \"gmc_sierra_2012\": [\"gmc_sierra_1500_2007\", \"gmc_sierra_1500_2008\", \"gmc_sierra_1500_2009\", \"gmc_sierra_1500_2010\", \"gmc_sierra_1500_2011\", \"gmc_sierra_1500_2012\", \"gmc_sierra_1500_2013\", \"gmc_sierra_2500_2007\", \"gmc_sierra_2500_2008\", \"gmc_sierra_2500_2009\", \"gmc_sierra_2500_2010\", \"gmc_sierra_2500_2011\", \"gmc_sierra_2500_2012\", \"gmc_sierra_2500_2013\"],\n",
    "    \"chevrolet_impala_2008\": [\"chevrolet_impala_2007\", \"chevrolet_impala_2008\", \"chevrolet_impala_2009\"]\n",
    "}\n",
    "\n",
    "\n",
    "full_dataset_path = \"Dataset/SubsetVMMR\"\n",
    "stolen_cars_path = \"Dataset/Most_Stolen_Cars\"\n",
    "\n",
    "if os.path.exists(stolen_cars_path):\n",
    "    shutil.rmtree(stolen_cars_path)\n",
    "else:\n",
    "    os.makedirs(stolen_cars_path)\n",
    "\n",
    "for directory, car_list in cars.items():\n",
    "    print(\"Creating\", directory)\n",
    "    car_directory_name = os.path.join(stolen_cars_path, directory)\n",
    "    os.makedirs(car_directory_name)\n",
    "    for car in car_list:\n",
    "        path = os.path.join(full_dataset_path, car, \"\")\n",
    "        files = glob.glob(path + '*.jpg')\n",
    "        for file in files:\n",
    "            shutil.copy(file, car_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_val_test_ratio = (.7,.1,.2) # 70/10/20 Data Split\n",
    "test_folder = 'Dataset/test/'\n",
    "train_folder = 'Dataset/train/'\n",
    "val_folder = 'Dataset/val/'\n",
    "\n",
    "files = glob.glob(stolen_cars_path + '/*/*.jpg') # Get all the files in the directory\n",
    "\n",
    "files_names = os.listdir(stolen_cars_path) # Get all the files in the directory\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "if os.path.exists(test_folder):\n",
    "    shutil.rmtree(test_folder)\n",
    "    \n",
    "if os.path.exists(train_folder):\n",
    "    shutil.rmtree(train_folder)\n",
    "    \n",
    "if os.path.exists(val_folder):\n",
    "    shutil.rmtree(val_folder)\n",
    "    \n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for file in files_names:\n",
    "    os.makedirs(train_folder + file)\n",
    "    os.makedirs(test_folder + file)\n",
    "    os.makedirs(val_folder + file)\n",
    "    \n",
    "#Split the data into Train and Test Folders\n",
    "for file in files:\n",
    "    if np.random.rand(1) < train_val_test_ratio[0]:\n",
    "        shutil.copy(file, train_folder + file.split('\\\\')[1] + '/' + file.split('\\\\')[2])\n",
    "    elif np.random.rand(1) < train_val_test_ratio[1]:\n",
    "        shutil.copy(file, val_folder + file.split('\\\\')[1] + '/' + file.split('\\\\')[2])\n",
    "    else:\n",
    "        shutil.copy(file, test_folder + file.split('\\\\')[1] + '/' + file.split('\\\\')[2])\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ratio of train, val, test\n",
    "train_files = glob.glob(train_folder + '/*/*.jpg')\n",
    "val_files = glob.glob(val_folder + '/*/*.jpg')\n",
    "test_files = glob.glob(test_folder + '/*/*.jpg')\n",
    "\n",
    "print(\"Train: \", len(train_files))\n",
    "print(\"Val: \", len(val_files))\n",
    "print(\"Test: \", len(test_files))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "#Select a random image and follow the next step\n",
    "datagen = ImageDataGenerator(rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                             zoom_range=0.3,  # Randomly zoom image\n",
    "                             vertical_flip=True, # randomly flip images\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             fill_mode=\"nearest\") # Fill in missing pixels with the nearest filled value\n",
    "#Load example image\n",
    "file_list = glob.glob(\"Dataset/test/*/*\") # Get all the files in the directory\n",
    "img_path = random.choice(file_list) # Select a random image\n",
    "img = load_img(img_path) # Load the image\n",
    "car_class = img_path.split(\"/\")[1] # Get the car class\n",
    "plt.imshow(img) # Show the image\n",
    "plt.axis(\"off\") # Remove axis\n",
    "plt.title(\"Original \" + car_class, fontsize=16) # Set title\n",
    "\n",
    "img = img_to_array(img) # Convert image to numpy array\n",
    "img = img.reshape((1,) + img.shape) # Reshape image\n",
    "#Apply different augmentation techniques\n",
    "n_augmentations = 4 # Number of augmentations to apply\n",
    "plt.figure(figsize=(15, 6))     # Set figure size\n",
    "i = 0 # Counter\n",
    "for batch in datagen.flow(img,  # Image to augment \n",
    "                          batch_size=1,  # Size of batch\n",
    "                          seed=21): # Seed for reproducibility\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1) # Create subplot\n",
    "    plt.imshow(array_to_img(batch[0])) # Show image\n",
    "    plt.axis(\"off\") # Remove axis\n",
    "    plt.suptitle(\"Augmented \" + car_class, fontsize=16) # Set title    \n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DataSet Generator with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train DataSet Generator with Augmentation\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_generator.flow_from_directory(\n",
    "        train_folder, # this is the target directory\n",
    "        target_size=(WIDTH, HEIGHT), # all images will be resized to 299x299\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    " \n",
    "val_generator = val_generator.flow_from_directory(\n",
    "        val_folder, # this is the target directory\n",
    "        target_size=(WIDTH, HEIGHT), # all images will be resized to 299x299\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    " \n",
    "test_generator = test_generator.flow_from_directory(\n",
    "        test_folder, # this is the target directory\n",
    "        target_size=(WIDTH, HEIGHT), # all images will be resized to 299x299\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling Minority Classes in Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(data_dir): # data_dir is the path to the folder containing the images to augment\n",
    "    list_of_images = os.listdir(data_dir) # Get list of images\n",
    "    datagen = ImageDataGenerator(rotation_range=45, \n",
    "        horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    for img_name in list_of_images: # Loop through images\n",
    "        tmp_img_name = os.path.join(data_dir, img_name) # Get full path to image\n",
    "        img = load_img(tmp_img_name)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        batch = datagen.flow(img,  # Image to augment\n",
    "            batch_size=1, \n",
    "            seed=21,\n",
    "            save_to_dir=data_dir, \n",
    "            save_prefix=img_name.split(\".jpg\")[0] + \"augmented\", \n",
    "            save_format=\"jpg\")\n",
    "\n",
    "        batch.next()\n",
    "\n",
    "classes_to_augment = [\n",
    "    \"toyota_camry_2014\",\n",
    "    \"nissan_altima_2014\",\n",
    "    \"toyota_corolla_2013\",\n",
    "    \"gmc_sierra_2012\"]\n",
    "\n",
    "for class_names in classes_to_augment:\n",
    "    print(\"Currently Augmenting:\", class_names)\n",
    "    data_dir = os.path.join(train_folder, class_names)\n",
    "    data_augment(data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Images to 299x299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize all images to 299x299\n",
    "\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "path = \"Dataset/train/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item + \"/\"):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((299,299), Image.ANTIALIAS)\n",
    "            # replace the original image with the resized one\n",
    "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
    "             \n",
    "resize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Selected Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygal\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Training Class Distribution'\n",
    "for o in os.listdir(train_folder):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(train_folder, o))))\n",
    "\n",
    "# show the plot\n",
    "line_chart.render_in_browser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from keras import optimizers, models\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "NUM_PARALLEL_EXEC_UNITS = 8 # Number of parallel execution units\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS, # Use 8 threads for intra-op parallelism\n",
    "                        inter_op_parallelism_threads=2, # Use 2 threads for inter-op parallelism\n",
    "                        allow_soft_placement=True, # Allow placement on CPU if a GPU is not available\n",
    "                        device_count = {'CPU': NUM_PARALLEL_EXEC_UNITS}) # Create a config object with the options specified above.\n",
    "\n",
    "session = tf.compat.v1.Session(config=config) # Create a session with the above options specified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MKL and OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(session)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(NUM_PARALLEL_EXEC_UNITS)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize InceptionV3 with transfer learning\n",
    "base_model = applications.InceptionV3(weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "                                include_top=False,  # Do not include the ImageNet classifier at the top.\n",
    "                                input_shape=(WIDTH, HEIGHT,3)) # Our images are 299x299 with 3 channels (RGB)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output # Get the output of the last layer of the InceptionV3 model\n",
    "\n",
    "x = GlobalAveragePooling2D()(x) # Add a pooling layer\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation='relu')(x) # Add a fully connected layer with 1024 hidden units and ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = train_generator\n",
    "predictions = Dense(len(train_flow.class_indices), activation='softmax')(x) # Add a final softmax layer for classification\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions) # Create a model based on the inputs and outputs\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers: # Loop through all the layers in the base model\n",
    "    layer.trainable = False # Set the layer to be non-trainable (weights will not be updated)\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy') # Compile the model\n",
    "model.summary() # Print a summary of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training / Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "val_flow = val_generator\n",
    "\n",
    "top_layers_file_path = \"models/iv3-top-layers.h5\"\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/iv3-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(top_layers_file_path)\n",
    "test_flow = test_generator\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Labels File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('iv3-labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "file_list = glob.glob(\"Dataset/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "print(\"Image Category: \", img_cat)\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print(\"Raw Predictions: \", preds)\n",
    "\n",
    "top_x = 3\n",
    "top_args = preds[0].argsort()[-top_x:][::-1]\n",
    "preds_label = [label[p] for p in top_args]\n",
    "print(\"\\nTop \" + str(top_x) + \" confidence: \" + \" \".join(map(str, sorted(preds[0])[-top_x:][::-1])))\n",
    "print(\"Top \" + str(top_x) + \" labels: \" + \" \".join(map(str, preds_label)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Keras Model to Tensorflow Frozen Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7735307a7b5a3c16fdcad706d4a822e2a128f734d94907b9b69ff76019723c76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
